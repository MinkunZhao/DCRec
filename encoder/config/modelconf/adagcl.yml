optimizer:
  name: adam
  lr: 1.0e-3
  weight_decay: 0

train:
  epoch: 3000
  batch_size: 4096
  save_model: false
  loss: pairwise
  log_loss: false
  test_step: 3
  reproducible: true
  seed: 2025
  patience: 5
  trainer: AdaGCLTrainer

test:
  metrics: [recall, ndcg]
  k: [5, 10, 20]
  batch_size: 1024

data:
  type: general_cf
  name: amazon

model:
  name: adagcl
  layer_num: 2
  reg_weight: 1.0e-5
  keep_rate: 0.8
  cl_weight: 1.0e-1
  ib_weight: 1.0e-2
  temperature: 0.5
  embedding_size: 128
  gamma: -0.45
  zeta: 1.05
  init_temperature: 2.0
  temperature_decay: 0.98
  lambda0: 1.0e-4

  # for amazon
  amazon:
    layer_num: 2
    reg_weight: 1.0e-5
    keep_rate: 0.98
    cl_weight: 1.0e-1
    ib_weight: 1.0e-2
    temperature: 0.5
    gamma: -0.45
    zeta: 1.05
    init_temperature: 2.0
    temperature_decay: 0.98
    lambda0: 1.0e-4

  # for yelp
  yelp:
    layer_num: 2
    reg_weight: 1.0e-5
    keep_rate: 0.98
    cl_weight: 1.0e-1
    ib_weight: 1.0e-2
    temperature: 0.5
    gamma: -0.45
    zeta: 1.05
    init_temperature: 2.0
    temperature_decay: 0.98
    lambda0: 1.0e-4

  # for steam
  steam:
    layer_num: 2
    reg_weight: 1.0e-5
    keep_rate: 0.98
    cl_weight: 1.0e-1
    ib_weight: 1.0e-2
    temperature: 0.5
    gamma: -0.45
    zeta: 1.05
    init_temperature: 2.0
    temperature_decay: 0.98
    lambda0: 1.0e-4
