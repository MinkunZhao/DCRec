optimizer:
  name: adam
  lr: 1.0e-3
  weight_decay: 0

train:
  epoch: 3000
  batch_size: 4096
  save_model: true
  loss: pairwise
  test_step: 3
  reproducible: true
  seed: 2025
  patience: 5

test:
  metrics: [recall, ndcg]
  k: [5, 10, 20]
  batch_size: 1024

data:
  type: general_cf
  name: amazon

model:
  name: sgl_llmrec
  # general parameters here
  keep_rate: 0.8
  embedding_size: 128
  augmentation: edge_drop

  # dataset-specific parameters here
  layer_num: 3
  reg_weight: 1.0e-5

  # for amazon
  amazon:
    layer_num: 3
    reg_weight: 1.0e-5
    cl_weight: 1.0e-1
    temperature: 0.2
    llm_weight: 5.0e-7
    fusion_temp: 0.2
  # for yelp
  yelp:
    layer_num: 3
    reg_weight: 1.0e-6
    cl_weight: 1.0e-3
    temperature: 0.1
    llm_weight: 5.0e-7
    fusion_temp: 0.2
  # for steam:
  steam:
    layer_num: 2
    reg_weight: 1.0e-5
    cl_weight: 1.0e-1
    temperature: 0.5
    llm_weight: 1.0e-6
    fusion_temp: 0.2
